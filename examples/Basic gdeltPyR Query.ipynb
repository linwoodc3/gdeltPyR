{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic `gdeltPyR` Usage\n",
    "\n",
    "`gdeltPyR` retrieves [Global Database of Events, Language, and Tone (GDELT) data (version 1.0 or version 2.0) ](http://gdeltproject.org/data.html#intro) via [parallel HTTP GET requests](http://docs.python-requests.org/en/v0.10.6/user/advanced/#asynchronous-requests) and is an alternative to [accessing GDELT data via Google BigQuery ](http://gdeltproject.org/data.html#googlebigquery). \n",
    "\n",
    " Performance will vary based on the number of available cores (i.e. CPUs), internet connection speed, and available RAM.  For systems with limited RAM, Later iterations of `gdeltPyR` will include an option to store the output directly to disc.  \n",
    "\n",
    "### Memory Considerations\n",
    "\n",
    "Take your systems specifications into consideration when running large or complex queries.  While `gdeltPyR` loads each temporary file long enough only to convert it into a `pandas` dataframe (15 minutes each for 2.0, full day for 1.0 events tables), GDELT data can be especially large and exhaust a computers RAM.  For example, Global Knowledge Graph (gkg) table queries can eat up large amounts of RAM when pulling data for only a few days.  Before trying month long queries, try single day queries or create a pipeline that pulls several days worth of data, writes to discs, flushes globals, and continues to pull more data.  \n",
    "\n",
    "### Recommended RAM\n",
    "\n",
    "It's best to use a system with at least 8 GB of RAM.\n",
    "\n",
    "# Installation\n",
    "\n",
    "```bash\n",
    "pip install gdeltPyR\n",
    "```\n",
    "\n",
    "You can also install directly from www.github.com\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/linwoodc3/gdeltPyR\n",
    "```\n",
    "\n",
    "# Basic Usage\n",
    "\n",
    "[`gdeltPyR`](https://github.com/linwoodc3/gdeltPyR) queries revolve around 4 concepts:\n",
    "\n",
    "| **Name** | **Description**                                                                                                                                                                                                                                                       | **Input Possibilities/Examples**    |\n",
    "|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------|\n",
    "| *version*  | (integer)  - Selects the version of GDELT data to query; defaults to version 2.                                                                                                                                                                                   | 1 or 2                          |\n",
    "| *date*    | (string or list of strings) - Dates to query                                                                                                                                                                                                                      | \"2016 10 23\" or \"2016 Oct 23\"   |\n",
    "| *coverage*| (bool) - For GDELT 2.0, pulls every 15 minute interval in the dates passed in the 'date' parameter. Default coverage is False or None.  `gdeltPyR` will pull the latest 15 minute interval for the current day or the last 15 minute interval for a historic day. | True or False or None           |\n",
    "| *tables*  | (string) - The specific GDELT table to pull.  The default table is the 'events' table.  See the [GDELT documentation page for more information](http://gdeltproject.org/data.html#documentation)                                                                  | 'events' or 'mentions' or 'gkg' |\n",
    "\n",
    "With these basic concepts, you can run any number of GDELT queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.13'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "# Import the package\n",
    "##############################\n",
    "import gdelt\n",
    "gdelt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "# Instantiate the gdelt object\n",
    "##############################\n",
    "\n",
    "gd = gdelt.gdelt(version=2,cores=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch your query, pass in your dates.  When passing multiple dates, pass as a list of strings.  We will time the multi-day query.  \n",
    "\n",
    "## Important Date Details for GDELT 1.0 and 2.0\n",
    "For **GDELT 2.0**, every 15 minute interval is a zipped CSV file, and `gdeltPyR` makes concurrent HTTP GET requests to each file. When the `coverage` parameter is set to *True*, each full day of data has 96 15 minute interval files to pull.  If you are pulling the current day and coverage is set to *True*, `gdeltPyR` all the intervals leading up to the latest 15 minute interval.  When `coverage` is *False*, the package pulls the last 15 minute interval when querying a historical date and the latest 15 minute interval when querying the current date. Additinally, GDELT 2.0 data only goes back as far as Feb 2015.  The [additional features of GDELT 2.0 are discussed here](http://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/). \n",
    "\n",
    "**GDELT 1.0** releases the previous day's query at 6AM EST of the next day (if today's current date is 23 Oct, the 22 Oct results would be available at 6AM Eastern on 23 Oct).\n",
    "\n",
    "# The Query\n",
    "\n",
    "To launch your query, just pass in dates.  When passing multiple dates, pass as a list of strings.  First, some information on my OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-14.1-x86_64-i386-64bit\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "print (platform.platform())\n",
    "\n",
    "print (multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 s, sys: 473 ms, total: 1.7 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%time results = gd.Search(['2023 10 19','2023 10 20'],table='events',coverage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an idea for the number of results we returned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 361591 entries, 0 to 361590\n",
      "Data columns (total 62 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   GLOBALEVENTID          361591 non-null  int64  \n",
      " 1   SQLDATE                361591 non-null  int64  \n",
      " 2   MonthYear              361591 non-null  int64  \n",
      " 3   Year                   361591 non-null  int64  \n",
      " 4   FractionDate           361591 non-null  float64\n",
      " 5   Actor1Code             331779 non-null  object \n",
      " 6   Actor1Name             331779 non-null  object \n",
      " 7   Actor1CountryCode      221099 non-null  object \n",
      " 8   Actor1KnownGroupCode   4609 non-null    object \n",
      " 9   Actor1EthnicCode       2266 non-null    object \n",
      " 10  Actor1Religion1Code    5234 non-null    object \n",
      " 11  Actor1Religion2Code    941 non-null     object \n",
      " 12  Actor1Type1Code        154085 non-null  object \n",
      " 13  Actor1Type2Code        10563 non-null   object \n",
      " 14  Actor1Type3Code        272 non-null     object \n",
      " 15  Actor2Code             273502 non-null  object \n",
      " 16  Actor2Name             273502 non-null  object \n",
      " 17  Actor2CountryCode      185627 non-null  object \n",
      " 18  Actor2KnownGroupCode   3606 non-null    object \n",
      " 19  Actor2EthnicCode       1797 non-null    object \n",
      " 20  Actor2Religion1Code    4901 non-null    object \n",
      " 21  Actor2Religion2Code    710 non-null     object \n",
      " 22  Actor2Type1Code        122200 non-null  object \n",
      " 23  Actor2Type2Code        7180 non-null    object \n",
      " 24  Actor2Type3Code        146 non-null     object \n",
      " 25  IsRootEvent            361591 non-null  int64  \n",
      " 26  EventCode              361591 non-null  object \n",
      " 27  CAMEOCodeDescription   361591 non-null  object \n",
      " 28  EventBaseCode          361591 non-null  object \n",
      " 29  EventRootCode          361591 non-null  object \n",
      " 30  QuadClass              361591 non-null  int64  \n",
      " 31  GoldsteinScale         361591 non-null  float64\n",
      " 32  NumMentions            361591 non-null  int64  \n",
      " 33  NumSources             361591 non-null  int64  \n",
      " 34  NumArticles            361591 non-null  int64  \n",
      " 35  AvgTone                361591 non-null  float64\n",
      " 36  Actor1Geo_Type         361591 non-null  int64  \n",
      " 37  Actor1Geo_FullName     324240 non-null  object \n",
      " 38  Actor1Geo_CountryCode  324306 non-null  object \n",
      " 39  Actor1Geo_ADM1Code     324306 non-null  object \n",
      " 40  Actor1Geo_ADM2Code     203898 non-null  object \n",
      " 41  Actor1Geo_Lat          324240 non-null  float64\n",
      " 42  Actor1Geo_Long         324271 non-null  float64\n",
      " 43  Actor1Geo_FeatureID    324306 non-null  object \n",
      " 44  Actor2Geo_Type         361591 non-null  int64  \n",
      " 45  Actor2Geo_FullName     267774 non-null  object \n",
      " 46  Actor2Geo_CountryCode  267842 non-null  object \n",
      " 47  Actor2Geo_ADM1Code     267842 non-null  object \n",
      " 48  Actor2Geo_ADM2Code     152893 non-null  object \n",
      " 49  Actor2Geo_Lat          267774 non-null  float64\n",
      " 50  Actor2Geo_Long         267804 non-null  float64\n",
      " 51  Actor2Geo_FeatureID    267842 non-null  object \n",
      " 52  ActionGeo_Type         361591 non-null  int64  \n",
      " 53  ActionGeo_FullName     353217 non-null  object \n",
      " 54  ActionGeo_CountryCode  353330 non-null  object \n",
      " 55  ActionGeo_ADM1Code     353330 non-null  object \n",
      " 56  ActionGeo_ADM2Code     198008 non-null  object \n",
      " 57  ActionGeo_Lat          353217 non-null  float64\n",
      " 58  ActionGeo_Long         353259 non-null  float64\n",
      " 59  ActionGeo_FeatureID    353330 non-null  object \n",
      " 60  DATEADDED              361591 non-null  int64  \n",
      " 61  SOURCEURL              361591 non-null  object \n",
      "dtypes: float64(9), int64(13), object(40)\n",
      "memory usage: 788.1 MB\n"
     ]
    }
   ],
   "source": [
    "results.info(memory_usage='deep',show_counts=True,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ~11 seconds, `gdeltPyR` returned several hundred thousand rows with 61 columns of data.  With the data in a tidy format, GDELT data can be analyzed with any number of [`pandas` data analysis pipelines and techniques](http://pandas.pydata.org/pandas-docs/stable/cookbook.html)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:analysis2]",
   "language": "python",
   "name": "conda-env-analysis2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
